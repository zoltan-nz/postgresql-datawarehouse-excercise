# Data Warehouse - Assignment 5 - SWEN 432

Zoltan Debre - 300360191

Original repository and progress history: https://github.com/zoltan-nz/postgresql-datawarehouse-excercise

Everything inserted in one runnable `sql` file which can be run with the following way if `dbname` exists:

```
$ psql --dbname=zoltan --file=./assignment-5.sql
```

The above command will import also the `dump` file. 

## Question 1 - A Data Mart in the PostgreSQL Environment
(12 marks)

**Create and populate `Book Orders Database` from `BookOrdersDatabaseDump_17.sql`.**

```
$ createdb zoltan
$ psql -d zoltan -f ./BookOrdersDatabaseDump_17.sql
```

A little database cleanup, renaming all `Sidney` to `Sydney`.

```
UPDATE customer SET city = 'Sydney' WHERE customer.city = 'Sidney';
UPDATE customer SET district = 'Povardarje' WHERE CustomerId = 96;
UPDATE customer SET district = 'Budapest' WHERE CustomerId = 100;
```

**Create `Data Mart` according to the description of its schema in Table 2.**

Populate it by extracting, transforming, and loading data from the operational “Book Orders Database”. Use PostgreSQL commands and functions to accomplish the tasks.

When building Time dimension, note that:

* `TimeId` should be a sequence generated by PostgreSQL. That sequence is associated with the `Cust_Order.OrderDate` values in an ascending manner (the earliest `Cust_Order.OrderDate` date is associated with the `TimeId = 1`).
* There are various PostgreSQL functions that allow automatic transformation of `Cust_Order.OrderDate` values into appropriate surrogates of `DayOfWeek`, `Month`, and real `Year` values.
* The `DayOfWeek` attribute takes values from the set {‘Monday’, ‘Tuesday’, ‘Wednesday’, ‘Thursday’, ‘Friday’, ‘Saturday’, ‘Sunday’)}.
* The `Month` attribute takes values from the set {‘January’, ‘February’, ‘March’, ‘April’, ‘May’, ‘June’, ‘July’, ‘August’, ‘September’, ‘October’, ‘November’, ‘December’}.


**Creating TIME table**

```sql
DROP TABLE IF EXISTS time;

CREATE TABLE time
(
  TimeId    SERIAL PRIMARY KEY NOT NULL,
  OrderDate DATE               NOT NULL,
  DayOfWeek VARCHAR(10)        NOT NULL,
  Month     VARCHAR(10)        NOT NULL,
  Year      INT                NOT NULL
);
CREATE UNIQUE INDEX time_TimeId_uindex ON time (TimeId);
```

* Populate from `cust_order` table:

```sql
INSERT INTO time (OrderDate, DayOfWeek, Month, Year)
  SELECT DISTINCT
    cust_order.orderdate                    AS OrderDate,
    to_char(cust_order.orderdate, 'Day')    AS DayOfWeek,
    to_char(cust_order.orderdate, 'Month')  AS Month,
    extract(YEAR FROM cust_order.orderdate) AS Year
  FROM cust_order
  ORDER BY OrderDate ASC;
```

Result:

```sql
SELECT COUNT(time.TimeId) FROM time;
 count
-------
   124
(1 row)
```
 

**Creating SALES table**

Note: `Amnt = SUM(Order_Detail.Quantity * Book.Price)`

Traditional way. We crate a table and insert data from other tables. (Below we can see a more efficient way to create sales aggregation with materialized view. I will use the materialized view `sales` table in this assignment.)  

```sql
CREATE TABLE sales_table
(
  customerid INTEGER       NOT NULL
    CONSTRAINT sales_customer_customerid_fk
    REFERENCES customer,
  timeid     INTEGER       NOT NULL
    CONSTRAINT sales_time_timeid_fk
    REFERENCES time,
  isbn       INTEGER       NOT NULL
    CONSTRAINT sales_book_isbn_fk
    REFERENCES book,
  amnt       NUMERIC(6, 2) NOT NULL,
  CONSTRAINT sales_customerid_timeid_isbn_pk PRIMARY KEY (customerid, timeid, isbn)
);

INSERT INTO sales_table (customerid, timeid, isbn, amnt)
  SELECT
    customer.customerid                     AS customerid,
    time.timeid                             AS timeid,
    book.isbn                               AS isbn,
    sum(order_detail.quantity * book.price) AS amnt
  FROM order_detail NATURAL JOIN book NATURAL JOIN cust_order NATURAL JOIN customer NATURAL JOIN time
  GROUP BY customer.customerid, time.timeid, book.isbn;
```

```

```


**Creating SALES_VIEW table (using materialized view)**

Note: `Amnt = SUM(Order_Detail.Quantity * Book.Price)`

This is an alternative approach, so we can use materialized view for storing sales aggregation.

```sql
DROP MATERIALIZED VIEW IF EXISTS sales CASCADE;

CREATE MATERIALIZED VIEW sales AS
  SELECT
    customer.customerid                                      AS CustomerId,
    time.timeid                                              AS TimeId,
    book.isbn                                                AS ISBN,
    sum(order_detail.quantity * book.price) :: numeric(6, 2) AS Amnt
  FROM book NATURAL JOIN order_detail NATURAL JOIN cust_order NATURAL JOIN customer NATURAL JOIN time
  GROUP BY customer.customerid, time.timeid, book.isbn
  ORDER BY CustomerId, TimeId, ISBN;
  
CREATE UNIQUE INDEX sales_CustomerIdTimeIdISBN_uindex ON sales (CustomerId, TimeId, ISBN);  
```

Result:

```sql
SELECT count(*) FROM sales;
 count
-------
  1070
(1 row)
```

## Question 2 - Aggregate Queries
(14 marks)

Find the average amount of money spent by all customers on buying books for all days so far.

Calculating averages from averages are wrong approach, we will get wrong results as we can see in the following queries:

```sql
CREATE MATERIALIZED VIEW avg_amnt_view AS
  SELECT
    CustomerId,
    avg(Amnt) AS avg_amnt
  FROM sales
  GROUP BY customerid;

SELECT 104
SELECT avg(avg_amnt) FROM avg_amnt_view;
         avg
----------------------
 202.9588687852809865
(1 row)
```

In the following case we calculate the average of all individual transactions. A transaction is amount of spending per customer per day per book.isbn. First I thought, this is not what we are looking for, but I got a message from my classmates, that we are looking for "the average money spent per customer, per day, per book.isbn". In this case the following solution is right, because our sales table's each row is unique for this three factors.


```sql
SELECT avg(amnt) FROM sales;
         avg
----------------------
 161.3691588785046729
(1 row)
```

But I think "average amount of money spent by all customers on buying books for all days" should remove the `book.isbn` as a property, so should combine book sales by customer and by day. Using two dimensional aggregation for calculating the average. Because I calculated and implemented that solution also, I just leave it here:

We are looking for the average amount of money spent by all customers for all days, so first we have to create a intermediate tuple. In this case each row represents a unique customer-day transaction. A customer can come back next day and could have a purchase, so it will be a unique row.

```
CREATE MATERIALIZED VIEW sum_customer_per_day AS
  SELECT
    customerid,
    timeid,
    sum(amnt) as amnt_spent_daily_by_customers
  FROM sales
  GROUP BY customerid, timeid;

SELECT 198
  
SELECT avg(amnt_spent_daily_by_customers) AS avg_spending_by_customers_per_day from sum_customer_per_day;

 avg_spending_by_customers_per_day
-----------------------------------
              872.0454545454545455
(1 row)  
```

Or we can calculate from the other direction. First creatin a materialized view which list the average spending by customer each day and using this avg and count to calculate our final daily avg spending.

```sql
CREATE MATERIALIZED VIEW avg_spending_by_customer_on_each_day AS
  SELECT
    timeid,
    count(customerid)                                       AS number_of_customer_a_day,
    avg(sum_customer_per_day.amnt_spent_daily_by_customers) AS avg_spending FROM sum_customer_per_day
  GROUP BY timeid;

SELECT 124

SELECT
  sum(avg_spending_by_customer_on_each_day.avg_spending * avg_spending_by_customer_on_each_day.number_of_customer_a_day)
  / sum(avg_spending_by_customer_on_each_day.number_of_customer_a_day) AS Total_AVG
FROM avg_spending_by_customer_on_each_day;

      total_avg
----------------------
 872.0454545454545455
```

## Question 3. OLAP Queries
(20 marks)

**a)** 

Use SQL to retrieve from your Data Mart: `customer id`’s, `names` and `surnames` of `five` customers who spent the **largest** amount of money buying books. This query uses two OLAP specific operations, name them.

(The result added to a materialized view, because we use it later.)

```sql
CREATE MATERIALIZED VIEW best_buyers AS
SELECT
  customer.CustomerId AS customer_id,
  customer.f_name     AS first_name,
  customer.l_name     AS last_name,
  sum(amnt)           AS spending
FROM sales
  NATURAL JOIN customer
GROUP BY customer.CustomerId
ORDER BY spending DESC LIMIT 5;

SELECT 5

SELECT * FROM best_buyers;

 customer_id |      first_name      |      last_name       | spending
-------------+----------------------+----------------------+----------
           1 | Kirk                 | Jacson               | 17810.00
           3 | Peter                | Andree               | 14100.00
          14 | Craig                | Anslow               | 11780.00
           2 | May-N                | Leow                 |  7145.00
          79 | Jiajun               | Liang                |  6095.00
(5 rows)
```

**Used OLAP operations:**

* *Dimensional roll-ups*, because we drop `book` and `time` dimension from our calculation.
* *Pivoting*, because we use three dimensions to aggregate our values for our `sales` table. 

**b)** 

Use SQL to find from your `Data Mart` and `the operational database` whether the customer who spent the greatest amount of money buying books did this by issuing many orders with smaller amounts or a few orders with greater amounts of money, or even great number of orders with greater amounts of money. Base your answer on an appropriate average value and the percentage of best buyer’s orders being smaller or greater than this average. What is the name of that OLAP specific operation? (You may use a stepwise procedure to solve the question.)

* `ord_avg_amnt`: the average amount of money of all orders

The first materialized view calculate the value of orders and after we calculate the average value of this list.
```sql
CREATE MATERIALIZED VIEW amount_per_order AS
  SELECT
    order_detail.orderid,
    sum(order_detail.quantity * book.price) AS order_amount
  FROM order_detail NATURAL JOIN book
  GROUP BY orderid;

SELECT 222

CREATE MATERIALIZED VIEW ord_avg_amnt AS
  SELECT avg(amount_per_order.order_amount) AS ord_avg_amnt
  FROM amount_per_order;

SELECT 1

SELECT * FROM ord_avg_amnt;

     ord_avg_amnt
----------------------
 777.7702702702702703
(1 row)
```

* `no_of_ord`: the number of orders issued by the customer who spent the greatest amount of money buying books (the best buyer)

```sql
CREATE MATERIALIZED VIEW no_of_ord AS
  SELECT count(cust_order.orderid) AS no_of_ord FROM cust_order
  WHERE cust_order.customerid IN (SELECT customer_id from best_buyers limit 1)
  GROUP BY cust_order.customerid;

SELECT 1

SELECT * FROM no_of_ord;

 no_of_ord
-----------
        14
(1 row)
```

* `perc_of_ord`: the percentage of orders issued by the best buyer that had a greater total amount than the ord_avg_amnt.

```sql
CREATE MATERIALIZED VIEW amount_per_order_by_customer AS
  SELECT
    order_detail.orderid,
    sum(order_detail.quantity * book.price) AS order_amount
  FROM order_detail NATURAL JOIN book NATURAL JOIN cust_order NATURAL JOIN customer
  WHERE cust_order.customerid IN (SELECT customer_id FROM best_buyers LIMIT 1)
  GROUP BY orderid;

SELECT 14
```

List of orders by the customers with amount:

```sql
SELECT * FROM amount_per_order_by_customer;
 orderid | order_amount
---------+--------------
     170 |       250.00
     107 |      2535.00
     111 |       915.00
       8 |      1245.00
      19 |      1120.00
     108 |      4165.00
       1 |       885.00
      21 |       395.00
     112 |       260.00
       4 |       925.00
     110 |      1910.00
       5 |       925.00
     172 |       450.00
     114 |      1830.00
(14 rows)
```

How many percentage above average:

```sql
CREATE MATERIALIZED VIEW perc_of_ord AS
  SELECT (count(*) * 100) :: NUMERIC / no_of_ord.no_of_ord AS perc_of_ord
  FROM amount_per_order_by_customer NATURAL JOIN ord_avg_amnt NATURAL JOIN no_of_ord
  WHERE amount_per_order_by_customer.order_amount > ord_avg_amnt.ord_avg_amnt
  GROUP BY no_of_ord.no_of_ord;
  
SELECT 1

SELECT * FROM perc_of_ord;

     perc_of_ord
---------------------
 71.4285714285714286
(1 row)
```

Conclusion:

```sql
SELECT perc_of_ord,
  CASE
    WHEN perc_of_ord >= 75
      THEN 'we estimate that the best buyer has issued a greater (than average) number of orders with 
      greater (than average) amounts of money'
    WHEN perc_of_ord < 75 AND perc_of_ord >= 50
      THEN 'we estimate that the best buyer has issued a greater (than average) to medium number of 
      orders with greater (than average) amounts of money'
    WHEN perc_of_ord < 50 AND perc_of_ord >= 25
      THEN 'we estimate that the best buyer has issued a small to medium number of orders with 
      greater (than average) amounts of money'
    WHEN perc_of_ord < 25
      THEN 'we estimate that the best buyer has issued a small number of orders with greater 
      (than average) amounts of money'
  END
FROM perc_of_ord;

     perc_of_ord     |                                                                    case
---------------------+----------------------------------------------------------------------------------------
 71.4285714285714286 | we estimate that the best buyer has issued a greater (than average) to medium number of 
                       orders with greater (than average) amounts of money
(1 row)
```
