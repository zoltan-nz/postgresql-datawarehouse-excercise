# Data Warehouse - Assignment 5 - SWEN 432

Zoltan Debre - 300360191

Original repository and progress history: https://github.com/zoltan-nz/postgresql-datawarehouse-excercise

## Question 1 - A Data Mart in the PostgreSQL Environment
(12 marks)

**Create and populate `Book Orders Database` from `BookOrdersDatabaseDump_17.sql`.**

```
$ createdb zoltan
$ psql -d zoltan -f ./BookOrdersDatabaseDump_17.sql
```

A little database cleanup, renaming all `Sidney` to `Sydney`.

```
UPDATE customer SET city = 'Sydney' WHERE customer.city = 'Sidney';
UPDATE customer SET district = 'Povardarje' WHERE CustomerId = 96;
UPDATE customer SET district = 'Budapest' WHERE CustomerId = 100;
```

**Create `Data Mart` according to the description of its schema in Table 2.**

Populate it by extracting, transforming, and loading data from the operational “Book Orders Database”. Use PostgreSQL commands and functions to accomplish the tasks.

When building Time dimension, note that:

* `TimeId` should be a sequence generated by PostgreSQL. That sequence is associated with the `Cust_Order.OrderDate` values in an ascending manner (the earliest `Cust_Order.OrderDate` date is associated with the `TimeId = 1`).
* There are various PostgreSQL functions that allow automatic transformation of `Cust_Order.OrderDate` values into appropriate surrogates of `DayOfWeek`, `Month`, and real `Year` values.
* The `DayOfWeek` attribute takes values from the set {‘Monday’, ‘Tuesday’, ‘Wednesday’, ‘Thursday’, ‘Friday’, ‘Saturday’, ‘Sunday’)}.
* The `Month` attribute takes values from the set {‘January’, ‘February’, ‘March’, ‘April’, ‘May’, ‘June’, ‘July’, ‘August’, ‘September’, ‘October’, ‘November’, ‘December’}.


**Creating TIME table**

```sql
DROP TABLE IF EXISTS time;

CREATE TABLE time
(
  TimeId    SERIAL PRIMARY KEY NOT NULL,
  OrderDate DATE               NOT NULL,
  DayOfWeek VARCHAR(10)        NOT NULL,
  Month     VARCHAR(10)        NOT NULL,
  Year      INT                NOT NULL
);
CREATE UNIQUE INDEX time_TimeId_uindex ON time (TimeId);
```

* Populate from `cust_order` table:

```sql
INSERT INTO time (OrderDate, DayOfWeek, Month, Year)
  SELECT DISTINCT
    cust_order.orderdate                    AS OrderDate,
    to_char(cust_order.orderdate, 'Day')    AS DayOfWeek,
    to_char(cust_order.orderdate, 'Month')  AS Month,
    extract(YEAR FROM cust_order.orderdate) AS Year
  FROM cust_order
  ORDER BY OrderDate ASC;
```

Result:

```sql
SELECT COUNT(time.TimeId) FROM time;
 count
-------
   124
(1 row)
```
 

**Creating SALES table**

Note: `Amnt = SUM(Order_Detail.Quantity * Book.Price)`

Traditional way. We crate a table and insert data from other tables. (Below we can see a more efficient way to create sales aggregation with materialized view.)  

```sql

```

**Creating SALES_VIEW table (using materialized view)**

Note: `Amnt = SUM(Order_Detail.Quantity * Book.Price)`

This is an alternative approach, so we can use materialized view for storing sales aggregation.

```sql
DROP MATERIALIZED VIEW IF EXISTS sales;

CREATE MATERIALIZED VIEW sales AS
  SELECT
    customer.customerid                     AS CustomerId,
    time.TimeId                             AS TimeId,
    book.isbn                               AS ISBN,
    sum(order_detail.quantity * book.price) AS Amnt
  FROM book NATURAL JOIN order_detail NATURAL JOIN cust_order NATURAL JOIN customer NATURAL JOIN time
  GROUP BY customer.customerid, TimeId, ISBN
  ORDER BY CustomerId, TimeId, ISBN;
  
CREATE UNIQUE INDEX sales_CustomerIdTimeIdISBN_uindex ON sales (CustomerId, TimeId, ISBN);  
```

Result:

```sql
SELECT count(*) FROM sales;
 count
-------
  1070
(1 row)
```

## Question 2 - Aggregate Queries
(14 marks)

Find the average amount of money spent by all customers on buying books for all days so far.

Calculating averages from averages are wrong approach, we will get wrong results as we can see in the following queries:

```sql
CREATE MATERIALIZED VIEW avg_amnt_view AS
  SELECT
    CustomerId,
    avg(Amnt) AS avg_amnt
  FROM sales
  GROUP BY customerid;

SELECT 104
SELECT avg(avg_amnt) FROM avg_amnt_view;
         avg
----------------------
 202.9588687852809865
(1 row)
```

In the following case we calculate the average of all individual transactions. A transaction is amount of spending per customer per day per book.isbn. First I thought, this is not what we are looking for, but I got a message from my classmates, that we are looking for "the average money spent per customer, per day, per book.isbn". In this case the following solution is right, because our sales table's each row is unique for this three factors.


```sql
SELECT avg(amnt) FROM sales;
         avg
----------------------
 161.3691588785046729
(1 row)
```

But I think "average amount of money spent by all customers on buying books for all days" should remove the `book.isbn` as a property, so should combine book sales by customer and by day. Using two dimensional aggregation for calculating the average. Because I calculated and implemented that solution also, I just leave it here:

We are looking for the average amount of money spent by all customers for all days, so first we have to create a intermediate tuple. In this case each row represents a unique customer-day transaction. A customer can come back next day and could have a purchase, so it will be a unique row.

```
CREATE MATERIALIZED VIEW sum_customer_per_day AS
  SELECT
    customerid,
    timeid,
    sum(amnt) as amnt_spent_daily_by_customers
  FROM sales
  GROUP BY customerid, timeid;

SELECT 198
  
SELECT avg(amnt_spent_daily_by_customers) AS avg_spending_by_customers_per_day from sum_customer_per_day;

 avg_spending_by_customers_per_day
-----------------------------------
              872.0454545454545455
(1 row)  
```

Or we can calculate from the other direction. First creatin a materialized view which list the average spending by customer each day and using this avg and count to calculate our final daily avg spending.

```sql
CREATE MATERIALIZED VIEW avg_spending_by_customer_on_each_day AS
  SELECT
    timeid,
    count(customerid)                                       AS number_of_customer_a_day,
    avg(sum_customer_per_day.amnt_spent_daily_by_customers) AS avg_spending FROM sum_customer_per_day
  GROUP BY timeid;

SELECT 124

SELECT
  sum(avg_spending_by_customer_on_each_day.avg_spending * avg_spending_by_customer_on_each_day.number_of_customer_a_day)
  / sum(avg_spending_by_customer_on_each_day.number_of_customer_a_day) AS Total_AVG
FROM avg_spending_by_customer_on_each_day;

      total_avg
----------------------
 872.0454545454545455
```

## Question 3. OLAP Queries
(20 marks)

a) Use SQL to retrieve from your Data Mart: `customer id`’s, `names` and `surnames` of `five` customers who spent the **largest** amount of money buying books. This query uses two OLAP specific operations, name them.

```sql
SELECT
  customer.CustomerId AS customer_id,
  customer.f_name     AS first_name,
  customer.l_name     AS last_name,
  sum(amnt)           AS spending
FROM sales
  NATURAL JOIN customer
GROUP BY customer.CustomerId
ORDER BY spending DESC LIMIT 5;

 customer_id |      first_name      |      last_name       | spending
-------------+----------------------+----------------------+----------
           1 | Kirk                 | Jacson               | 17810.00
           3 | Peter                | Andree               | 14100.00
          14 | Craig                | Anslow               | 11780.00
           2 | May-N                | Leow                 |  7145.00
          79 | Jiajun               | Liang                |  6095.00
(5 rows)
```

**OLAP operations:**

* *Dimensional roll-ups*, because we drop `book` and `time` dimension from our calculation.
* *Pivoting*, because for our `sales` table we use three dimensions to aggregate our values

